# Отчет по лабораторной работе №2

## Задание №1

### Сравнение скорости вычислений суммы (от 1 до 10000000000000)

| Метод           | Время выполнения (сек) |
|-----------------|------------------------|
| Threading       | 0.16                   |
| Multiprocessing | 0.19                   |
| Asyncio         | 0.15                   |

Во всех трёх программах я посчитала сумму большого диапазона чисел, но с использованием разных подходов: потоки, процессы и асинхронность.

**Asyncio** оказался самым быстрым **(0.15 сек)**, потому что работает легко и быстро в одном потоке без переключения контекста.
**Threading** показал чуть медленнее **(0.16 сек)** — работает хорошо, но из-за GIL в Python не даёт настоящего параллелизма.
**Multiprocessing** был самым медленным **(0.19 сек)**, потому что запускает отдельные процессы, а это занимает немного больше времени.

Все методы справились с задачей, но asyncio оказался немного быстрее остальных именно для такой простой задачи.


## Задание №2

В этом задании было реализовано три программы для параллельного парсинга нескольких веб-страниц с сохранением данных в базу данных.

**1) Программа threading_parser.py**

threading_parser.py использует многопоточность (threading) для параллельной загрузки веб-страниц. Потоки работают в одном процессе и делят между собой память, что упрощает доступ к общим ресурсам, но ограничено GIL. Подходит для I/O-задач, но требует аккуратного управления сессиями базы данных, чтобы избежать конфликтов при записи.

**2) Программа multiprocessing_parser.py**

multiprocessing_parser.py реализует параллелизм через multiprocessing, создавая отдельный процесс для каждого URL. Этот подход обходит GIL и позволяет использовать все ядра процессора, что особенно эффективно при больших объёмах данных. Несмотря на немного больший overhead по сравнению с потоками, показал лучшее время выполнения в тесте.

**3) Программа async_parser.py**

async_parser.py использует асинхронный подход с asyncio и aiohttp для одновременной загрузки страниц без потоков и процессов. Он идеально подходит для обработки множества сетевых запросов за счёт неблокирующего ввода-вывода. Однако в тесте оказался медленнее из-за возможных задержек со стороны сайтов и последовательной записи в базу данных.

### Сравнение времени выполнения

| Подход          | Время выполнения (сек) | Комментарий                                                |
|-----------------|------------------------|------------------------------------------------------------|
| Threading       | 4.92                   | Подходит для I/O-задач, но ограничен GIL.                  |
| Multiprocessing | 4.85                   | Использует процессы, обходит GIL, чуть быстрее.            |
| Asyncio         | 10.12                  | Эффективен для I/O, но зависит от скорости отклика сайтов. |

### Анализ результатов

- Multiprocessing оказался немного быстрее, чем threading, благодаря реальному параллелизму и отсутствию GIL.
- Threading дал результат чуть медленнее, но тоже хорошо справился, особенно учитывая простоту реализации.
- Asyncio, вопреки ожиданиям, оказался самым медленным. Вероятно, задержка была связана с соединением с одним или несколькими сайтами, которые долго отвечали (например, `ticktick.com` иногда возвращал `503`).
Это показывает, что асинхронность эффективна при массовых запросах, но при небольшом количестве URL или нестабильных сайтах — может не дать преимущества.

Подведя итог, можно сказать, что для небольшого числа URL наиболее эффективным оказался `multiprocessing`, но `asyncio` лучше использовать при большом потоке данных и стабильных I/O.


